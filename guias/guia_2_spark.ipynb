{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codeado por Franco M. Di Maria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guia 2 : Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones auxiliares "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "FORMATO_FECHA = '%Y-%m-%d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "# By Tom Alsberg and Boris (StackOverflow) \n",
    "def str_time_prop(start, end, format, prop):\n",
    "    \"\"\"Get a time at a proportion of a range of two formatted times.\n",
    "\n",
    "    start and end should be strings specifying times formated in the\n",
    "    given format (strftime-style), giving an interval [start, end].\n",
    "    prop specifies how a proportion of the interval to be taken after\n",
    "    start.  The returned time will be in the specified format.\n",
    "    \"\"\"\n",
    "\n",
    "    stime = time.mktime(time.strptime(start, format))\n",
    "    etime = time.mktime(time.strptime(end, format))\n",
    "\n",
    "    ptime = stime + prop * (etime - stime)\n",
    "\n",
    "    return time.strftime(format, time.localtime(ptime))\n",
    "\n",
    "\n",
    "def random_date(start, end):\n",
    "    return str_time_prop(start, end, FORMATO_FECHA, random.random())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-Se tiene un RDD con el registro de notas de los alumnos de la forma (padrón, materia, nota, fecha). Se pide resolver utilizando PySpark:\n",
    "* A.Cuántos alumnos aprobaron al menos 1 materia en los últimos 2 años.\n",
    "* B. Un RDD conteniendo el promedio de notas de cada alumno de la forma (padrón, promedio).\n",
    "* C.El nombre y apellido del alumno con mejor promedio. Para esto pued eutilizarse un segundo RDD alumnos con registros (padron, nombre y apellido)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data_1_notas = [\n",
    "    (100498, 'Datos', 10, '2019-9-16'),\n",
    "    (100499, 'Datos', 9, '2019-9-17'),\n",
    "    (100500, 'Datos', 8, '2019-9-18'),\n",
    "    (100501, 'Datos', 7, '2019-9-19'),\n",
    "    (100502, 'Datos', 7, '2019-9-20'),\n",
    "    (100498, 'Taller', 9, '2019-6-1'),\n",
    "    (100499, 'Taller', 6, '2019-6-2'),\n",
    "    (100500, 'Taller', 8, '2019-6-3'),\n",
    "    (100501, 'Taller', 8, '2019-6-4'),\n",
    "    (100502, 'Taller', 9, '2019-6-5'),\n",
    "    (100498, 'Proba', 8, '2018-11-11'),\n",
    "    (100499, 'Proba', 6, '2018-11-12'),\n",
    "    (100500, 'Proba', 6, '2018-11-13'),\n",
    "    (100501, 'Proba', 7, '2018-11-14'),   \n",
    "    (100502, 'Proba', 8, '2018-11-15'),\n",
    "]\n",
    "\n",
    "rdd_1 = sc.parallelize(pre_data_1_notas)\n",
    "#rdd_1.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.Cuántos alumnos aprobaron al menos 1 materia en los últimos 2 años."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RESOLUCION 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_1.filter( lambda x: (x[2] >= 4) & (x[3] > \"2018-1-1\") & (x[3] < \"2018-12-31\") )\\\n",
    "    .map( lambda x: x[0] )\\\n",
    "    .distinct()\\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RESOLUCION 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_1.filter( lambda x: (x[2] >= 4) & (x[3] > \"2018-1-1\") & (x[3] < \"2018-12-31\") )\\\n",
    "    .flatMap( lambda x: (x[0],) )\\\n",
    "    .distinct()\\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RESOLUCION 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_1.filter( lambda x: (x[2] >= 4) & (x[3] > \"2018-1-1\") & (x[3] < \"2018-12-31\") )\\\n",
    "    .map( lambda x: (x[0],1) )\\\n",
    "    .reduceByKey( lambda x, y: x )\\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Un RDD conteniendo el promedio de notas de cada alumno de la forma (padrón, promedio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(100498, 9.0),\n",
       " (100499, 7.0),\n",
       " (100500, 7.333333333333333),\n",
       " (100501, 7.333333333333333),\n",
       " (100502, 8.0)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_1_promedios = rdd_1.map( lambda x: (x[0], (x[2], 1)) )\\\n",
    "                    .reduceByKey( lambda x, y: (x[0] + y[0], x[1] + y[1]) )\\\n",
    "                    .map( lambda x: (x[0], x[1][0] / x[1][1]) )\n",
    "rdd_1_promedios.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.El nombre y apellido del alumno con mejor promedio. Para esto puede utilizarse un segundo RDD alumnos con registros (padron, nombre y apellido)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set de datos auxiliar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data_1_alumnos = [\n",
    "    (100498, 'Franco Martin', 'Di Maria'),\n",
    "    (100499, 'Alumno B', 'Ble Ble'),\n",
    "    (100500, 'Alumno C', 'Bli Bli'),\n",
    "    (100501, 'Alumno D', 'Blo Blo'),\n",
    "    (100502, 'Alumno E', 'Blu Blu'),\n",
    "]\n",
    "\n",
    "rdd_1_alumnos = sc. parallelize(pre_data_1_alumnos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RESOLUCION 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(100498, 'Franco Martin Di Maria', 9.0)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_1_alumnos_por_padron = rdd_1_alumnos.map( lambda x: (x[0], x[1] + ' ' + x[2]) )\n",
    "padron_promedio_max = rdd_1_promedios.reduce(lambda x, y: x if x[1] > y[1] else y)\n",
    "rdd_1_alumnos_por_padron.filter(lambda x: x[0] == padron_promedio_max[0])\\\n",
    "    .map(lambda x: (x[0], x[1], padron_promedio_max[1]) )\\\n",
    "    .take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RESOLUCION 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100498, 'Franco Martin Di Maria', 9.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_1_alumnos_por_padron = rdd_1_alumnos.map( lambda x: (x[0], x[1] + ' ' + x[2]) )\n",
    "rdd_1_alumnos_por_padron.join(rdd_1_promedios)\\\n",
    "    .map( lambda x: (x[0], x[1][0], x[1][1]) )\\\n",
    "    .reduce( lambda x, y: x if x[2] > y[2] else y )\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Se tiene un RDD registros de ventas de producto con la forma (fecha de venta, código de\n",
    "producto, precio de venta) y en otro RDD detalle de los productos con (código de producto,\n",
    "descripción del producto, categoría). Se pide resolver utilizando PySpark:\n",
    "* A. Cuál es el producto más vendido.\n",
    "* B. Cuál es la categoría de productos más vendida.\n",
    "* C. Cuál es el top5 de productos más vendidos generando un RDD con (código de producto, descripción, cantidad de ventas)\n",
    "* D. Cuál es el producto que registró mayor aumento de precio en el último año, tomando para este análisis solo los productos que cuenten con al menos 50 ventas en el último año.\n",
    "* E. Idem anterior, pero calculando la categoría de productos que registró mayor variación de precios en el último año."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sets de datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data_2_ventas = []\n",
    "pre_data_2_detalles = []\n",
    "cant_productos = 10\n",
    "codigo_productos = [i for i in range(cant_productos)]\n",
    "for _ in range(500):\n",
    "    pre_data_2_ventas.append( \n",
    "        ( random_date('2018-1-1', '2019-12-31'), random.choice(codigo_productos), random.uniform(100, 1000) ) \n",
    "    )\n",
    "for i in range(cant_productos):\n",
    "    pre_data_2_detalles.append( \n",
    "        ( i, 'Descripcion ...' , random.choice(['Categ. A', 'Categ. B', 'Categ. C']) ) \n",
    "    )\n",
    "rdd_2_ventas = sc.parallelize(pre_data_2_ventas)\n",
    "rdd_2_detalles = sc.parallelize(pre_data_2_detalles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Cuál es el producto más vendido. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_2_ventas.map( lambda x: (x[1], 1) )\\\n",
    "    .reduceByKey( lambda x, y: x + y )\\\n",
    "    .reduce(lambda x, y: x if x[1] > y[1] else y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_2_producto_cant = rdd_2_ventas.map( lambda x: (x[1], 1) )\\\n",
    "                        .reduceByKey(lambda x, y: x + y)\n",
    "rdd_2_producto_cant.takeOrdered(1, lambda x: -x[1])[0][0] # Pues devuelve una lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 56),\n",
       " (8, 51),\n",
       " (1, 44),\n",
       " (9, 49),\n",
       " (2, 57),\n",
       " (3, 53),\n",
       " (4, 56),\n",
       " (5, 38),\n",
       " (6, 45),\n",
       " (7, 51)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_2_producto_cant.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede pasar que haya dos productos con igual cantidad de ventas, por lo que las dos operaciones anteriores puede dar distinto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Cuál es la categoría de productos más vendida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Categ. C'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nos quedamos con rdd (codigo_producto, cantidad)\n",
    "rdd_2_producto_cant = rdd_2_ventas.map( lambda x: (x[1], 1) )\\\n",
    "                        .reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "# Nos quedamos con un rdd (codigo_producto, categoria)\n",
    "rdd_2_producto_categ = rdd_2_detalles.map( lambda x: (x[0], x[2]) )\n",
    "\n",
    "# Joineamos a partir de la misma clave : codigo_producto, obteniedo un rdd : \n",
    "# ( codigo_producto, (cantidad, categoria) )\n",
    "rdd_2_producto_cant_categ = rdd_2_producto_cant.join(rdd_2_producto_categ)\n",
    "\n",
    "# Llevamos la categoria a la clave y nos quedamos solo con la cantidad de \n",
    "# repeticiones de esa categoria para cada producto. Como se pueden repetir\n",
    "# la misma categoria para mas de un producto, debemos sumar las cantidades\n",
    "# para una misma categoria, y luego reducir para quedarno con la categoria \n",
    "# mas vendida\n",
    "rdd_2_producto_cant_categ.map( lambda x: (x[1][1], x[1][0]) )\\\n",
    "    .reduceByKey(lambda x, y: x + y)\\\n",
    "    .reduce(lambda x, y: x if x[1] > y[1] else y)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Cuál es el top 5 de productos más vendidos generando un RDD con (código de producto, descripción, cantidad de ventas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 'Descripcion ...', 57),\n",
       " (0, 'Descripcion ...', 56),\n",
       " (4, 'Descripcion ...', 56),\n",
       " (3, 'Descripcion ...', 53),\n",
       " (8, 'Descripcion ...', 51)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_2_producto_descripcion = rdd_2_detalles.map(lambda x: (x[0], x[1]) )\n",
    "\n",
    "rdd_2_producto_cant_top_5 = sc.parallelize(rdd_2_producto_cant.takeOrdered(5, lambda x: -x[1]))\n",
    "\n",
    "rdd_2_producto_cant_descripcion = rdd_2_producto_cant_top_5.join(rdd_2_producto_descripcion)\n",
    "\n",
    "rdd_2_producto_cant_descripcion.map(lambda x: (x[0], x[1][1], x[1][0]) )\\\n",
    "    .takeOrdered(5, lambda x: -x[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Cuál es el producto que registró mayor aumento de precio en el último año, tomando para este análisis solo los productos que cuenten con al menos 50 ventas en el último año. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomemos 5 en lugar de 50, por el set que tenemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 515.3526455511341)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minima_cant_ventas = 5 # 50\n",
    "rdd_2_productos_considerar = rdd_2_ventas.filter(lambda x:  (x[0] < '2019-10') & (x[0] > '2018-10') )\\\n",
    "                                .map(lambda x: (x[1], 1 ) )\\\n",
    "                                .reduceByKey(lambda x, y: (x + y))\\\n",
    "                                .filter(lambda x: x[1] >= minima_cant_ventas)\n",
    "\n",
    "rdd_2_productos_considerar_completo = rdd_2_ventas.map(lambda x: (x[1], (x[0], x[2]) ) )\\\n",
    "                                        .join(rdd_2_productos_considerar)\\\n",
    "                                        .map(lambda x: (x[0], (x[1][0][0], x[1][0][1]) ) )\n",
    "# (codigo_producto, ( (fecha, precio), cantidad ) ) => (codigo_producto, (fecha, precio) )\n",
    "\n",
    "\n",
    "rdd_2_precios_finales = rdd_2_productos_considerar_completo\\\n",
    "                            .reduceByKey(lambda vx, vy: vx if vx[0] > vy[0] else vy)\\\n",
    "                            .map(lambda x: (x[0], x[1][1])) # (codigo_producto, precio) # finales\n",
    "\n",
    "rdd_2_precios_iniciales = rdd_2_productos_considerar_completo\\\n",
    "                            .reduceByKey(lambda vx, vy: vx if vx[0] < vy[0] else vy)\\\n",
    "                            .map(lambda x: (x[0], x[1][1]) ) # (codigo_producto, precio) # iniciales\n",
    "\n",
    "\n",
    "rdd_2_precio_diff_porcental = rdd_2_precios_iniciales.join(rdd_2_precios_finales)\n",
    "# (codigo_producto, (precio_inicial, precio_final) )\n",
    "\n",
    "\n",
    "rdd_2_precio_diff_porcental.map(lambda x: (x[0], x[1][1] * 100 / x[1][0]))\\\n",
    "    .reduce(lambda x, y: x if x[1] > y[1] else y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Idem anterior, pero calculando la categoría de productos que registró mayor variación de precios en el último año."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Categ. C', 559.3095975782546)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_2_categorias_considerar = rdd_2_productos_considerar_completo.join(rdd_2_detalles.map(lambda x: (x[0], x[2])))\\\n",
    "                                .map(lambda x: (x[1][1], (x[1][0]) ))\n",
    "# (codigo_producto, ( (fecha, precio), categoria ) ) => (categoria, (fecha, precio))\n",
    "\n",
    "rdd_2_precios_categ_final = rdd_2_categorias_considerar.reduceByKey(lambda vx, vy: vx if vx[0] > vy[0] else vy)\\\n",
    "                                .map(lambda x: (x[0], x[1][1]) )\n",
    "\n",
    "rdd_2_precios_categ_inicial = rdd_2_categorias_considerar.reduceByKey(lambda vx, vy: vx if vx[0] < vy[0] else vy)\\\n",
    "                                .map(lambda x: (x[0], x[1][1]) )\n",
    "# (categoria, precio) # en ambos de arriba\n",
    "\n",
    "rdd_2_precio_categ_diff_porcental = rdd_2_precios_categ_inicial.join(rdd_2_precios_categ_final)\n",
    "# (categoria, (precio_inicial, precio_final))\n",
    "\n",
    "rdd_2_precio_categ_diff_porcental.map(lambda x: (x[0], x[1][1] * 100 / x[1][0]) )\\\n",
    "    .reduce(lambda x, y: x if x[1] > y[1] else y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Se tiene un RDD con información de vuelos programados con la forma (número de vuelo, código de aerolínea, código de aeropuerto de salida, código de aeropuerto de llegada, fecha de salida AAAAMMDD, hora de salida HH:MM, fecha de llegada AAAAMMDD, hora de llegada HH:MM). A su vez, se cuenta con el registro actualizado del estado de los vuelos que fueron ocurriendo, con la forma (número de vuelo, aerolínea, fecha de salida AAAAMMDD, hora de salida HH:MM, fecha de llegada AAAAMMDD, hora de llegada HH:MM, estado). En base al estado, podría contar con algún dato en blanco, por ejemplo si el vuelo fue cancelado no tendrá información de fechas y horas, si el vuelo se encuentra aún en curso, no contendrá información de la llegada. Se pide resolver utilizando PySpark:\n",
    "* A. Cuál es el aeropuerto con mayor tránsito.\n",
    "* B. Cuál es la aerolínea con mayor cantidad de vuelos.\n",
    "* C. Cuál es la aerolínea con mayor cantidad de cancelaciones.\n",
    "* D. Cuál es el vuelo (numero de vuelo + fecha) con mayor retraso en el horario de salida.\n",
    "* E. Cuál es el vuelo (numero de vuelo + fecha) con mayor retraso en el horario de llegada.\n",
    "* F. Cuál es la aerolínea más puntual.\n",
    "* G. Cuál es el aeropuerto que registra mayor desviación con respecto a los horarios coordinados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-01-02'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dia = datetime.datetime.strptime('2019-1-1', FORMATO_FECHA)\n",
    "dia += datetime.timedelta(days=1)\n",
    "dia.strftime(FORMATO_FECHA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "CANCELADO = 'CANCELADO'\n",
    "EN_CURSO = 'EN CURSO'\n",
    "FINALIZADO = 'FINALIZADO'\n",
    "pre_data_3_programa_vuelos = [\n",
    "    ('Vuelo 0', 'Aerolinea 0', 'Aeropuerto Salida 0', 'Aeropuerto llegada 4', '20190113', '02:00','20190113', '04:00'),\n",
    "    ('Vuelo 1', 'Aerolinea 0', 'Aeropuerto Salida 1', 'Aeropuerto llegada 4', '20190214', '02:30','20190114', '04:00'),\n",
    "    ('Vuelo 2', 'Aerolinea 0', 'Aeropuerto Salida 1', 'Aeropuerto llegada 5', '20190315', '06:00','20190115', '12:00'),\n",
    "    ('Vuelo 3', 'Aerolinea 0', 'Aeropuerto Salida 1', 'Aeropuerto llegada 5', '20190416', '17:00','20190116', '18:30'),\n",
    "    ('Vuelo 4', 'Aerolinea 1', 'Aeropuerto Salida 2', 'Aeropuerto llegada 6', '20190517', '20:30','20190117', '22:00'),\n",
    "    ('Vuelo 5', 'Aerolinea 1', 'Aeropuerto Salida 3', 'Aeropuerto llegada 7', '20190618', '23:30','20190118', '01:00'),\n",
    "]\n",
    "\n",
    "pre_data_3_estado_vuelos = [\n",
    "    ('Vuelo 0', 'Aerolinea 0', '20190113', '02:00','20190113', '05:00', FINALIZADO),\n",
    "    ('Vuelo 1', 'Aerolinea 0', '20190214', '03:00','20190114', '04:30', FINALIZADO),\n",
    "    ('Vuelo 2', 'Aerolinea 0', '', '', '', '', CANCELADO),\n",
    "    ('Vuelo 3', 'Aerolinea 0', '', '', '', '', CANCELADO),\n",
    "    ('Vuelo 4', 'Aerolinea 1', '', '', '', '', CANCELADO),\n",
    "    ('Vuelo 5', 'Aerolinea 1', '20190619', '00:30','', '', EN_CURSO),\n",
    "]\n",
    "\n",
    "rdd_3_programa = sc.parallelize(pre_data_3_programa_vuelos)\n",
    "rdd_3_estado = sc.parallelize(pre_data_3_estado_vuelos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Cuál es el aeropuerto con mayor tránsito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aeropuerto Salida 1'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Necesito aeropuerto salida y llegada\n",
    "rdd_3_aeropuerto_salida = rdd_3_programa.map( lambda x: (x[2], 1) )\\\n",
    "                            .reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "rdd_3_aeropuerto_llegada = rdd_3_programa.map( lambda x: (x[3], 1) )\\\n",
    "                            .reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "rdd_3_aeropuerto = rdd_3_aeropuerto_salida.union(rdd_3_aeropuerto_llegada)\n",
    "\n",
    "rdd_3_aeropuerto.reduceByKey(lambda x, y: x + y)\\\n",
    "    .reduce(lambda x, y: x if x[1] > y[1] else y)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Cuál es la aerolínea con mayor cantidad de vuelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aerolinea 0'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_3_programa.map( lambda x: (x[1], 1) )\\\n",
    "    .reduceByKey(lambda x, y: x + y)\\\n",
    "    .reduce(lambda x, y: x if x[1] > y[1] else y)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Cuál es la aerolínea con mayor cantidad de cancelaciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aerolinea 0'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_3_estado.filter(lambda x: x[6] == CANCELADO)\\\n",
    "    .map(lambda x: (x[1], 1))\\\n",
    "    .reduceByKey(lambda x, y: x + y)\\\n",
    "    .reduce(lambda x, y: x if x[1] > y[1] else y)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Cuál es el vuelo (numero de vuelo + fecha) con mayor retraso en el horario de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Vuelo 5', '2019-06-18 23:30')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_3_horario_salida_teor = rdd_3_programa.map(lambda x: (\n",
    "                                                x[0], \n",
    "                                                datetime.datetime.combine(\n",
    "                                                    datetime.datetime.strptime(x[4], '%Y%m%d').date(),\n",
    "                                                    datetime.datetime.strptime(x[5], '%H:%M').time()\n",
    "                                                ) \n",
    "                                            ))\n",
    "\n",
    "rdd_3_horario_salida_real = rdd_3_estado.filter(lambda x: x[6] != CANCELADO)\\\n",
    "                                .map(lambda x: (\n",
    "                                    x[0],\n",
    "                                    datetime.datetime.combine(\n",
    "                                        datetime.datetime.strptime(x[2], '%Y%m%d').date(),\n",
    "                                        datetime.datetime.strptime(x[3], '%H:%M').time()\n",
    "                                    )\n",
    "                                ))\n",
    "# Supongo que no hay vuelos repetidos con distinto valor e ninguno de los dos rdds\n",
    "rdd_3_horario_salida_delta = rdd_3_horario_salida_teor.join(rdd_3_horario_salida_real)\n",
    "# ('Vuelo i', (datetime_teor, datetime_real) )\n",
    "\n",
    "rdd_3_horario_salida_delta = rdd_3_horario_salida_delta.map(lambda x: (\n",
    "                                                            x[0], \n",
    "                                                            (\n",
    "                                                                x[1][0].strftime('%Y-%m-%d %H:%M'), \n",
    "                                                                x[1][1] - x[1][0]\n",
    "                                                            ) \n",
    "                                                        ))\n",
    "\n",
    "# ('Vuelo i, (Fecha teor, timedelta)')\n",
    "vuelo_mas_restrasado_salida = rdd_3_horario_salida_delta.reduce(lambda x, y: x if x[1][1] > y[1][1] else y)\n",
    "vuelo_mas_restrasado_salida = (vuelo_mas_restrasado_salida[0], vuelo_mas_restrasado_salida[1][0])\n",
    "vuelo_mas_restrasado_salida # (Vuelo i, Fecha de llegada teor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Cuál es el vuelo (numero de vuelo + fecha) con mayor retraso en el horario de llegada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Vuelo 0', '2019-01-13 04:00')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_3_horario_llegada_teor = rdd_3_programa.map(lambda x: (\n",
    "                                                x[0], \n",
    "                                                datetime.datetime.combine(\n",
    "                                                    datetime.datetime.strptime(x[6], '%Y%m%d').date(),\n",
    "                                                    datetime.datetime.strptime(x[7], '%H:%M').time()\n",
    "                                                ) \n",
    "                                            ))\n",
    "\n",
    "rdd_3_horario_llegada_real = rdd_3_estado.filter(lambda x: x[6] == FINALIZADO)\\\n",
    "                                .map(lambda x: (\n",
    "                                    x[0],\n",
    "                                    datetime.datetime.combine(\n",
    "                                        datetime.datetime.strptime(x[4], '%Y%m%d').date(),\n",
    "                                        datetime.datetime.strptime(x[5], '%H:%M').time()\n",
    "                                    )\n",
    "                                ))\n",
    "# Supongo que no hay vuelos repetidos con distinto valor e ninguno de los dos rdds\n",
    "rdd_3_horario_llegada_delta = rdd_3_horario_llegada_teor.join(rdd_3_horario_llegada_real)\n",
    "# ('Vuelo i', (datetime_teor, datetime_real) )\n",
    "\n",
    "rdd_3_horario_llegada_delta = rdd_3_horario_llegada_delta.map(lambda x: (\n",
    "                                                            x[0], \n",
    "                                                            (\n",
    "                                                                x[1][0].strftime('%Y-%m-%d %H:%M'), \n",
    "                                                                x[1][1] - x[1][0]\n",
    "                                                            ) \n",
    "                                                        ))\n",
    "\n",
    "# ('Vuelo i, (Fecha teor, timedelta)')\n",
    "vuelo_mas_restrasado_llegada = rdd_3_horario_llegada_delta.reduce(lambda x, y: x if x[1][1] > y[1][1] else y)\n",
    "vuelo_mas_restrasado_llegada = (vuelo_mas_restrasado_llegada[0], vuelo_mas_restrasado_llegada[1][0])\n",
    "vuelo_mas_restrasado_llegada # (Vuelo i , fecha llegada teor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. Cuál es la aerolínea más puntual. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Sera la aerolinea que tenga sume un timedelta menor.  \n",
    " Podemos tener en cuenta tanto horario de salida como de llegada.  \n",
    " Descartamos vuelos cancelados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aerolinea 1'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ya tengo timedelta salida, llegada por vuelo => puedo joinear y reducir por Aerolinea\n",
    "rdd_3_salida_delta = rdd_3_horario_salida_delta.map(lambda x: (x[0], x[1][1]))\n",
    "rdd_3_llegada_delta = rdd_3_horario_llegada_delta.map(lambda x: (x[0], x[1][1]))\n",
    "rdd_3_vuelos_aerolineas = rdd_3_estado.map(lambda x: (x[0], x[1]) )\n",
    "\n",
    "rdd_3_horario_salida_delta_aerolinea = rdd_3_vuelos_aerolineas.join(rdd_3_salida_delta)\\\n",
    "                                            .map( lambda x: (x[1][0], x[1][1]) )\\\n",
    "                                            .reduceByKey(lambda x, y: x + y)\n",
    "rdd_3_horario_llegada_delta_aerolinea = rdd_3_vuelos_aerolineas.join(rdd_3_llegada_delta)\\\n",
    "                                            .map( lambda x: (x[1][0], x[1][1]) )\\\n",
    "                                            .reduceByKey(lambda x, y: x + y)\n",
    "rdd_3_horario_delta_aerolinea = rdd_3_horario_salida_delta_aerolinea.union(rdd_3_horario_llegada_delta_aerolinea)\\\n",
    "                                    .reduceByKey( lambda x, y: x + y)\n",
    "rdd_3_horario_delta_aerolinea.reduce(lambda x, y: x if x[1] < y[1] else y)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Cuál es el aeropuerto que registra mayor desviación con respecto a los horarios coordinados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aeropuerto llegada 4'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_3_vuelo_salida_delta = rdd_3_horario_salida_delta.map(lambda x: (x[0], x[1][1]))\n",
    "rdd_3_vuelo_llegada_delta = rdd_3_horario_llegada_delta.map(lambda x: (x[0], x[1][1]))\n",
    "rdd_3_vuelos_aeropuertos_salida = rdd_3_programa.map(lambda x: (x[0], x[2]) )\n",
    "rdd_3_vuelos_aeropuertos_llegada = rdd_3_programa.map(lambda x: (x[0], x[3]) )\n",
    "\n",
    "# Supongo horario coordinado de un aeropuerto como horario de salida ó llegada, \n",
    "# segun sea un aeropuerto de salida ó llegada, respectivamente \n",
    "\n",
    "rdd_3_aeropuerto_salida_delta = rdd_3_vuelos_aeropuertos_salida.join(rdd_3_vuelo_salida_delta)\\\n",
    "                                            .map( lambda x: (x[1][0], x[1][1]) )\\\n",
    "                                            .reduceByKey(lambda x, y: x + y)\n",
    "rdd_3_aeropuerto_llegada_delta = rdd_3_vuelos_aeropuertos_llegada.join(rdd_3_vuelo_llegada_delta)\\\n",
    "                                            .map( lambda x: (x[1][0], x[1][1]) )\\\n",
    "                                            .reduceByKey(lambda x, y: x + y)\n",
    "rdd_3_aeropuerto_delta = rdd_3_aeropuerto_salida_delta.union(rdd_3_aeropuerto_llegada_delta)\\\n",
    "                                    .reduceByKey( lambda x, y: x + y)\n",
    "rdd_3_aeropuerto_delta.reduce(lambda x, y: x if x[1] > y[1] else y)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- Se tiene un RDD con las coordenadas de rectángulos de la forma (x1,x2,y1,y2). Se pide programar en PySpark un programa que encuentre el rectángulo de superficie mínima que contiene al punto (w,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data_4_rectangulos = [\n",
    "    (0,3,0,3),\n",
    "    (1,2,1,2),\n",
    "    (-2,4,-2,4),\n",
    "    (-1,1,-1,1),\n",
    "    (-1,-2,-1,-2)\n",
    "]\n",
    "\n",
    "punto_4 = (1.5,1.5)\n",
    "\n",
    "rdd_4_rectangulos = sc.parallelize(pre_data_4_rectangulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 1, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_4_rectangulos.filter(lambda x: (x[0] <= punto_4[0] <= x[1]) and (x[2] <= punto_4[1] <= x[3]))\\\n",
    "                    .map(lambda x: (x, (x[1]-x[0])*(x[3]-x[2]) ))\\\n",
    "                    .reduce(lambda x, y: x if x[1] < y[1] else y)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5- Se tiene un RDD con libros en donde cada registro es un texto. Se pide obtener todos los anagramas de mas de 7 letras que puedan encontrarse. El formato de salida debe ser una lista de listas en donde cada lista tiene un conjunto de palabras que son anagramas. Ejemplo: [ [discounter, introduces, reductions], [percussion, supersonic]..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data_5_textos = [\n",
    "    ('The amazing discounter reductions'),\n",
    "    ('Introduces the new anagrama'),\n",
    "    ('The percussion of supersonic'),\n",
    "    ('Alexander the great')\n",
    "]\n",
    "\n",
    "rdd_5_textos = sc.parallelize(pre_data_5_textos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion auxiliar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supongo que los textos no tienen comas ni signos de puntacion.\n",
    "# Si los tiene, los tomo como parte de la palabra\n",
    "def obtener_anagrama_en_orden_alfabetico(palabra):\n",
    "    \"\"\"\n",
    "    PRE: Recibe una palabra (string)\n",
    "    POST: Devuelve un anagrama de dicha palabra, \n",
    "    cuyas letras estan ordenadas alfabeticamente.\n",
    "    \"\"\"\n",
    "    palabra_minuscula = palabra.lower()\n",
    "    letras = list(palabra_minuscula)\n",
    "    letras.sort()\n",
    "    return ''.join(letras)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['anagrama'],\n",
       " ['Alexander'],\n",
       " ['discounter', 'reductions', 'Introduces'],\n",
       " ['percussion', 'supersonic']]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_5_textos.flatMap(lambda x: x.split(' '))\\\n",
    "    .filter(lambda x: len(x) > 7)\\\n",
    "    .map( lambda x: (obtener_anagrama_en_orden_alfabetico(x), [x]) )\\\n",
    "    .reduceByKey(lambda x, y: x + y)\\\n",
    "    .map(lambda x: x[1] ).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 6 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6- UBER almacena en un cluster todos los datos sobre el movimiento y viajes de todos sus vehículos. Existe un proceso que nos devuelve un RDD llamado trip_summary con los siguientes campos: (driver_id, car_id, trip_id, customer_id, date (YYYYMMDD), distance_traveled), Programar usando PySpark un programa que nos indique cual fue el conductor con mayor promedio de distancia recorrida por viaje para Abril de 2016."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
